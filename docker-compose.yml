version: '2.1'
services:

  mininet:
    container_name: mininet
    build:
      context: services/mininet/
    ports:
      - "38080:38080"
      - "17191:17191"
    privileged: true
    volumes:
      - /lib/modules:/lib/modules
    depends_on:
      logstash:
        condition: service_started
    networks:
      default:
        aliases:
         - mininet.pendev

  neo4j:
    container_name: neo4j
    hostname: neo4j.pendev
    image: "kilda/neo4j:${full_build_number:-latest}"
    ports:
      - "7474:7474"
      - "7687:7687"
      - "16010:16010"
      - "16011:16011"
    healthcheck:
      test: ["CMD-SHELL", "curl --fail http://localhost:7474/"]
      interval: 30s
      timeout: 10s
      retries: 3
    networks:
      default:
        aliases:
         - neo4j.pendev


##
## Python based topology-engine
##
  topology-engine:
    container_name: topology-engine
    hostname: topology-engine.pendev
    build:
      context: services/topology-engine/
      dockerfile: Dockerfile
    image: "kilda/topology-engine:${full_build_number:-latest}"
    command: ./entrypoint.sh
    environment:
      neo4jhost: 'neo4j'
      neo4juser: 'neo4j'
      neo4jpass: 'temppass'
      neo4jbolt: 'http://neo4j:7474/db/data/cypher'
      bootstrapserver: 'kafka.pendev:9092'
      speaker_in_topic: 'speaker.in'
      group: 'python-tpe-tl-consumer'
      OK_TESTS: "${OK_TESTS:-none}"
    depends_on:
      kafka:
        condition: service_healthy
      neo4j:
        condition: service_healthy
      logstash:
        condition: service_started
    networks:
      default:
        aliases:
         - topology-engine.pendev


  topology-engine-rest:
    container_name: topology-engine-rest
    hostname: topology-engine-rest.pendev
    build:
      context: services/topology-engine-rest/
      dockerfile: Dockerfile
    image: "kilda/topology-engine-rest:${full_build_number:-latest}"
    volumes:
      - app_server_data:/var/data
    ports:
      - "80:80"
    environment:
      neo4jhost: 'neo4j'
      neo4juser: 'neo4j'
      neo4jpass: 'temppass'
      neo4jbolt: 'http://neo4j:7474/db/data/cypher'
      bootstrapserver: 'kafka.pendev:9092'
      speaker_in_topic: 'speaker.in'
      group: 'python-tpe-tl-consumer'
      OK_TESTS: "${OK_TESTS:-none}"
    depends_on:
      kafka:
        condition: service_healthy
      neo4j:
        condition: service_healthy
      logstash:
        condition: service_started
    networks:
      default:
        aliases:
         - topology-engine-rest.pendev


  zookeeper:
    container_name: zookeeper
    hostname: zookeeper.pendev
    image: "kilda/zookeeper:${full_build_number:-latest}"
    command: /opt/zookeeper/bin/zkServer.sh start-foreground
    ports:
      - "2181:2181"
    healthcheck:
      test: ["CMD-SHELL", "jps | grep --silent QuorumPeer"]
      interval: 30s
      timeout: 10s
      retries: 3
    networks:
      default:
        aliases:
         - zookeeper.pendev


  kafka:
    container_name: kafka
    hostname: kafka.pendev
    image: "kilda/kafka:${full_build_number:-latest}"
    # run_and_configure is in services/kafka/kafka-conf
    command: /opt/kafka/bin/run_and_configure.sh
    # command: /opt/kafka/bin/kafka-server-start.sh /opt/kafka/config/server.properties
    volumes:
      - kafka_data:/data/kafka
    depends_on:
      zookeeper:
        condition: service_healthy
    ports:
      - "9092:9092"
    extra_hosts:
      - "kafka.pendev:127.0.0.1"
    healthcheck:
      test: ["CMD-SHELL", "jps | grep --silent Kafka"]
      interval: 30s
      timeout: 10s
      retries: 3
    networks:
      default:
        aliases:
         - kafka.pendev


  wfm:
    container_name: wfm
    build:
      context: services/wfm
    image: "kilda/wfm:${full_build_number:-latest}"
    depends_on:
      kafka:
        condition: service_healthy
      zookeeper:
        condition: service_healthy
      storm-nimbus:
        condition: service_healthy
      storm-supervisor:
        condition: service_healthy


  hbase:
    container_name: hbase
    hostname: hbase.pendev
    image: "kilda/hbase:${full_build_number:-latest}"
    command: /opt/hbase/bin/start-hbase
    volumes:
      - hbase_data:/data/hbase
    depends_on:
      zookeeper:
        condition: service_healthy
    ports:
      - "60000:60000"
      - "60010:60010"
      - "60020:60020"
      - "60030:60030"
      - "8070:8070"
      - "8090:8090"
      - "9070:9070"
      - "9080:9080"
      - "9090:9090"
    healthcheck:
      test: ["CMD-SHELL", "jps | grep --silent HMaster"]
      interval: 30s
      timeout: 10s
      retries: 3
    networks:
      default:
        aliases:
         - hbase.pendev


  storm-nimbus:
    container_name: storm-nimbus
    hostname: nimbus.pendev
    image: "kilda/storm:${full_build_number:-latest}"
    command: /app/wait-for-it.sh -t 120 -h zookeeper.pendev -p 2181 -- /opt/storm/bin/storm nimbus
    depends_on:
      zookeeper:
        condition: service_healthy
      opentsdb:
        condition: service_started
    ports:
      - "6627:6627"
      - "3772:3772"
      - "3773:3773"
      - "8000:8000"
    healthcheck:
      test: ["CMD-SHELL", "jps | grep --silent nimbus"]
      interval: 30s
      timeout: 10s
      retries: 3
    networks:
      default:
        aliases:
         - storm-nimbus.pendev
         - nimbus.pendev


  storm-ui:
    container_name: storm-ui
    image: "kilda/storm:${full_build_number:-latest}"
    command: /app/wait-for-it.sh -t 120 -h zookeeper.pendev -p 2181 -- /opt/storm/bin/storm ui
    depends_on:
      zookeeper:
        condition: service_healthy
      storm-nimbus:
        condition: service_healthy
      storm-supervisor:
        condition: service_healthy
    ports:
      - "8888:8080"
    healthcheck:
      test: ["CMD-SHELL", "jps | grep --silent core"]
      interval: 30s
      timeout: 10s
      retries: 3
    networks:
      default:
        aliases:
         - storm-ui.pendev


  storm-supervisor:
    container_name: storm-supervisor
    hostname: storm-supervisor.pendev
    image: "kilda/storm:${full_build_number:-latest}"
    command: /app/wait-for-it.sh -t 120 -h zookeeper.pendev -p 2181 -- /opt/storm/bin/storm supervisor
    depends_on:
      zookeeper:
        condition: service_healthy
      storm-nimbus:
        condition: service_healthy
      logstash:
        condition: service_started
      opentsdb:
        condition: service_started
    ports:
      - "6700:6700"
      - "6701:6701"
      - "6702:6702"
      - "6703:6703"
      - "6704:6704"
      - "6705:6705"
      - "6706:6706"
      - "6707:6707"
      - "6708:6708"
      - "6709:6709"
      - "6710:6710"
      - "6711:6711"
      - "6712:6712"
      - "6713:6713"
      - "6714:6714"
      - "8001:8000"
    healthcheck:
      test: ["CMD-SHELL", "jps | grep --silent Supervisor"]
      interval: 30s
      timeout: 10s
      retries: 3
    networks:
      default:
        aliases:
         - storm-supervisor.pendev


  floodlight:
    container_name: floodlight
    build:
      context: services/src/floodlight-modules
    image: "kilda/floodlight:${full_build_number:-latest}"
    ports:
      - "6653:6653"
      - "8180:8080"
      - "6655:6655"
      - "6642:6642"
      - "8081:8080"
    depends_on:
      kafka:
        condition: service_healthy
      logstash:
        condition: service_started
    networks:
      default:
        aliases:
         - floodlight.pendev
# we use kilda as hostname for FL in atdd topologies
         - kilda


  northbound:
    container_name: openkilda-northbound
    build:
      context: services/src/northbound/
    ports:
      - "8088:8080"
    environment:
      REST_USERNAME: 'kilda'
      REST_PASSWORD: 'kilda'
    depends_on:
      kafka:
        condition: service_healthy
      logstash:
        condition: service_started
    networks:
      default:
        aliases:
         - northbound.pendev


  opentsdb:
    container_name: opentsdb
    hostname: opentsdb.pendev
    image: "kilda/opentsdb:${full_build_number:-latest}"
    command: /app/wait-for-it.sh -t 120 -h hbase.pendev -p 9090 -- /app/start-opentsdb
    depends_on:
      zookeeper:
        condition: service_healthy
      hbase:
        condition: service_healthy
    ports:
      - "4242:4242"
    networks:
      default:
        aliases:
         - opentsdb.pendev


  gui:
    container_name: gui
    build:
      context: services/src/openkilda-gui
    ports:
      - "8010:1010"
    depends_on:
      northbound:
        condition: service_started
      opentsdb:
        condition: service_started
    networks:
      default:
        aliases:
         - openkilda-gui.pendev


  elasticsearch:
    container_name: elasticsearch
    image: elasticsearch:5.6.5
    hostname: elasticsearch.pendev
    ports:
      - "127.0.0.1:9200:9200"
      - "127.0.0.1:9300:9300"
    networks:
      default:
        aliases:
         - elasticsearch.pendev


  kibana:
    image: kibana:5.6.5
    container_name: kibana
    hostname: kibana.pendev
    depends_on:
      elasticsearch:
        condition: service_started
    ports:
      - 5601:5601
    networks:
      default:
        aliases:
         - kibana.pendev


  logstash:
    container_name: logstash
    hostname: logstash.pendev
    image: "kilda/logstash:${full_build_number:-latest}"
    depends_on:
      elasticsearch:
        condition: service_started
    ports:
      - 9600:9600
    networks:
      default:
        aliases:
         - logstash.pendev


volumes:
  zookeeper_data:
  kafka_data:
  app_server_data:
  hbase_data:

version: '2.1'
services:

  zookeeper:
    container_name: zookeeper
    hostname: zookeeper.kilda
    image: "kilda/zookeeper:${full_build_number:-latest}"
    command: /opt/zookeeper/bin/zkServer.sh start-foreground
    ports:
      - "2181:2181"
    healthcheck:
      test: ["CMD-SHELL", "jps | grep --silent QuorumPeer"]
      interval: 30s
      timeout: 10s
      retries: 3
    networks:
      default:
        aliases:
          - zookeeper.kilda
    mem_limit: ${ZOOKEEPER_MEM_LIMIT:-1073741824}

  kafka:
    container_name: kafka
    hostname: kafka.kilda
    # image: "kilda/kafka:${full_build_number:-latest}"
    build:
      context: services/kafka/
      dockerfile: Dockerfile
    # run_and_configure is in services/kafka/kafka-conf
    command: /opt/kafka/bin/run_and_configure.sh
    # command: /opt/kafka/bin/kafka-server-start.sh /opt/kafka/config/server.properties
    volumes:
      - kafka_data:/data/kafka
    depends_on:
      zookeeper:
        condition: service_healthy
    ports:
      - "9092:9092"
    extra_hosts:
      - "kafka.kilda:127.0.0.1"
    healthcheck:
      test: ["CMD-SHELL", "jps | grep --silent Kafka"]
      interval: 30s
      timeout: 10s
      retries: 3
    networks:
      default:
        aliases:
          - kafka.kilda
    environment:
      KAFKA_HEAP_OPTS: "-XX:+PrintFlagsFinal -XX:+UnlockExperimentalVMOptions -XX:+UseCGroupMemoryLimitForHeap -XshowSettings:all"
    mem_limit: ${KAFKA_MEM_LIMIT:-1073741824}

  elasticsearch:
    container_name: elasticsearch
    image: "kilda/elasticsearch:${full_build_number:-latest}"
    build:
      context: services/elasticsearch/
      dockerfile: Dockerfile
    hostname: elasticsearch.kilda
    ports:
      - "9200:9200"
      - "9300:9300"
    networks:
      default:
        aliases:
          - elasticsearch.kilda
    environment:
      ES_JAVA_OPTS: "-XX:+PrintFlagsFinal -XX:+UnlockExperimentalVMOptions -XX:+UseCGroupMemoryLimitForHeap"
    mem_limit: ${ELASTIC_MEM_LIMIT:-1073741824}


  kibana:
    image: kibana:5.6.12
    container_name: kibana
    hostname: kibana.kilda
    depends_on:
      elasticsearch:
        condition: service_started
    ports:
      - 5601:5601
    networks:
      default:
        aliases:
          - kibana.kilda
    mem_limit: ${KIBANA_MEM_LIMIT:-1073741824}


  prometheus:
    image: prom/prometheus:v2.14.0
    container_name: prometheus
    hostname: prometheus.kilda
    depends_on:
      elasticsearch:
        condition: service_started
    ports:
      - "9090:9090"
    networks:
      default:
        aliases:
          - prometheus.kilda
    volumes:
      - ${PWD}/services/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml
    mem_limit: ${PROMETHEUS_MEM_LIMIT:-1073741824}


  logstash:
    container_name: logstash
    hostname: logstash.kilda
    image: "kilda/logstash:${full_build_number:-latest}"
    depends_on:
      elasticsearch:
        condition: service_started
    ports:
      - "9600:9600"
    networks:
      default:
        aliases:
          - logstash.kilda
    environment:
      LS_JAVA_OPTS: "-XX:+PrintFlagsFinal -XX:+UnlockExperimentalVMOptions -XX:+UseCGroupMemoryLimitForHeap -XshowSettings:all"
      LS_OPTS: "--debug-config"
      # remove default 500m heap size in /usr/share/logstash/vendor/jruby/bin/jruby
      JAVA_MEM: " "
    mem_limit: ${LOGSTASH_MEM_LIMIT:-1073741824}

volumes:
  zookeeper_data:
  kafka_data:

networks:
  default:
    ipam:
      config:
        # use that ip for communicate between control app and services
        - subnet: "10.0.100.1/24"
